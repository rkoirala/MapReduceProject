/**
 *
 * @author rachana
 */

package com.algorithm.pairs;

import java.io.IOException;
import java.util.ArrayList;
import java.util.HashMap;
import java.util.List;
import java.util.StringTokenizer;

import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Mapper;

public class RelativeFrequencyMapper extends
	Mapper<Object, Text, Text, IntWritable>  {

	private static HashMap<Pair, Integer> pairs = new HashMap<Pair, Integer>();
	List<Long> ipList = new ArrayList<Long>();
	Context op;
	IntWritable s = new IntWritable();
	
	public void map(Object key, Text value, Context output) throws IOException,
    InterruptedException {
		op = output;
		StringTokenizer ipValues = new StringTokenizer(value.toString());
		while (ipValues.hasMoreTokens()) {
			ipList.add(Long.parseLong(ipValues.nextToken()));
		}

		// If more than one word is present, split using white space.
		Pair p = new Pair();
		Pair p0 = new Pair();
		for (int i = 0; i < ipList.size() - 2; i++) {

			for (int j = i + 1; j < ipList.size() - 1; j++) {

				p.setB(ipList.get(j));
				p.setA(ipList.get(i));
				p0.setA(ipList.get(i));
				p0.setB(0);

				if (ipList.get(i) == ipList.get(j))
					break;

				if (pairs.containsKey(p)) {
					pairs.put(p, pairs.get(p) + 1);
					pairs.put(p0, pairs.get(p0) + 1);
				}

				else {
					pairs.put(p0, 1);
					pairs.put(p, 1);
					p0 = new Pair();
					p = new Pair();
				}
			}
		}
		
		 for(Pair pa:pairs.keySet()){
         	 s.set(pairs.get(p));
         	 
         }
	}
}