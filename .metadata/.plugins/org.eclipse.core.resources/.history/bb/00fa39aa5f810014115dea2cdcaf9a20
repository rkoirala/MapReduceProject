/**
*
* @author rachana
*/

package com.algorithm.pairs;

import java.io.IOException;
import java.util.Iterator;

import org.apache.hadoop.io.DoubleWritable;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.RecordWriter;
import org.apache.hadoop.mapreduce.Reducer;
import org.apache.hadoop.mapreduce.Reducer.Context;


public class RelativeFrequencyReducer extends Reducer<Pair, IntWritable, Pair, DoubleWritable> {
	
	double recentPairCount=0;
	DoubleWritable freq = new DoubleWritable();
	
	@Override
    public void reduce(Pair key, Iterable<IntWritable> count, Context output)
            throws IOException, InterruptedException {
        int total = 0;
        while(count.hasNext()){
            total+= count.next().get();
        }
        if(key.neighbor()==0)
        	recentPairCount=total;
        else
        {
        	freq.set(total/recentPairCount);
        	output.collect(key,freq );
        }
    }
}
