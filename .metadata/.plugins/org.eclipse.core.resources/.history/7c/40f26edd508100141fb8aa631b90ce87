package com.algorithm.pairs;

import java.io.IOException;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.mapred.FileInputFormat;
import org.apache.hadoop.mapred.FileOutputFormat;
import org.apache.hadoop.mapred.JobClient;
import org.apache.hadoop.mapred.JobConf;
import org.apache.hadoop.mapred.TextInputFormat;
import org.apache.hadoop.mapred.TextOutputFormat;

public class Application {

	 public static void main(String[] args) throws IOException {
	    	if (args.length != 2) {
	            System.out.println("usage: [input] [output]");
	            System.exit(-1);
	        }

	        JobConf job = new JobConf(Application.class);
	        job.setJobName("Pairs Approach");
	        
	        job.setOutputKeyClass(Pair.class);
	        job.setOutputValueClass(IntWritable.class);

	        job.setMapperClass(RelativeFrequencyMapper.class);
	        job.setReducerClass(RelativeFrequencyReducer.class);
	        job.setPartitionerClass(RelativeFrequencyPartitioner.class);
	        
	        

	        job.setInputFormat(TextInputFormat.class);
	        job.setOutputFormat(TextOutputFormat.class);

	        FileInputFormat.setInputPaths(job, new Path(args[0]));
	        FileOutputFormat.setOutputPath(job, new Path(args[1]));   
	        
	        JobClient.runJob(job);
	    }
	 
}
